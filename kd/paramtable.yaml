# =======================================================================
# Stream2segment config file to tune the processing/visualization routine
# =======================================================================

# NOTE: This file is written in YAML syntax, which uses Python-style indentation to
# indicate nesting, keep it in mind when editing. You can also use a more compact format
# that uses [] for lists and {} for maps/objects. For info see:
# http://docs.ansible.com/ansible/latest/YAMLSyntax.html
#
# If this file is passed as -c argument to the `s2s process` or `s2s show` command,
# everything implemented here will be accessible in the argument `config` of any 
# processing / plot function implemented in the associated Python file, but please note 
# that some parameters (e.g. 'segments_selection', 'sn_windows' and 'advanced_settings')
# are also used outside those functions to tune the whole routine (see details below)


# Define which segments to process or visualize. For details, see:
# https://github.com/rizac/stream2segment/wiki/the-segment-object#segments-selection
# (scroll to the top of the page for the full list of selectable attributes)
# THIS PARAMETER SHOULD BE ALWAYS PROVIDED: if missing or empty, all segments will be 
# loaded, including segment with missing or malformed waveform data. This is rarely what
# you might want and slows down considerably the processing or visualization routine
segments_selection:
  has_data: 'true'
  maxgap_numsamples: '[-0.5, 0.5]'
  missing_data_sec: '<120'
  missing_data_ratio: '<0.5'
  id: '<33'
  event.time: "(2022-11-01T00:00:00, 2022-11-08T23:59:59)"
  #event.latitude: "[24, 70]"
  #event.longitude: "[-11, 24]"

# Settings for computing the 'signal' and 'noise' time windows on a segment waveform.
# From within the GUI, signal and noise windows will be visualized as shaded areas on the
# plot of the currently selected segment. If this parameter is missing, the areas will
# not be shown.
#
# Arrival time shift: shifts the calculated arrival time of
# each segment by the specified amount of time (in seconds). Negative values are allowed.
# The arrival time is used to split a segment into segment's noise (before the arrival
# time) and segment's signal (after)
#
# Signal window: specifies the time window of the segment's signal, in seconds from the
# arrival time. If not numeric it must be a 2-element numeric array, denoting the start
# and end points, relative to the squares cumulative of the segment's signal portion.
# E.g.: [0.05, 0.95] sets the signal window from the time the cumulative reaches 5% of
# its maximum, until the time it reaches 95% of its maximum.
# The segment's noise window will be set equal to the signal window (i.e., same duration)
# and shifted in order to always end on the segment's arrival time
sn_windows:
  arrival_time_shift: -2.0  # programmatically shifts the arrival time for every segment (in seconds)
  signal_window: [0.1, 0.9]  # either a number (in seconds) or interval relative to the % of the cumulative


# settings for the sn (signal-to-noise) spectra implemented in the associated python module
sn_spectra:
  taper:
    max_percentage: 0.05
    type: 'hann'
  smoothing_wlen_ratio: 0.05  # 0 for no smoothing
  type: 'amp'  # if 'pow', then power spectra are computed, otherwise if 'amp', amplitude spectra are computed
  
# settings for the pre-process function implemented in the associated python module
preprocess:
  remove_response_water_level: 60
  remove_response_output: 'ACC'
  bandpass_freq_max: 30  # the max frequency, in Hz:
  bandpass_max_nyquist_ratio: 0.9
  bandpass_corners: 2

# settings for the wood-anderson implemented in the associated python module
paz_wa:
  sensitivity: 2800
  zeros:
    - '0j'
  poles:
    - '-6.2832-4.7124j'
    - '-6.2832+4.7124j'
  gain: 1

# savitzky_golay:
savitzky_golay:
  wsize: 31  # window size in pts
  order: 4   # polynomial order to use to fit and smooth data
  deriv: 2   # the derivative (1st, second, ...)

# thresholds for the multievent (heuristic) algorithm
multievent_thresholds:
  inside_tmin_tmax_inpercent: 0.90
  inside_tmin_tmax_insec: 10.0
  after_tmax_inpercent: 0.10

# other custom parameters used in the associated python module
amp_ratio_threshold: 0.8
snr_threshold: 3
freqs_interp:
 - 0.1
 - 0.106365
 - 0.113136
 - 0.120337
 - 0.127997
 - 0.136145
 - 0.144811
 - 0.154028
 - 0.163833
 - 0.174261
 - 0.185354
 - 0.197152
 - 0.209701
 - 0.22305
 - 0.237248
 - 0.252349
 - 0.268412
 - 0.285497
 - 0.30367
 - 0.323
 - 0.34356
 - 0.365429
 - 0.388689
 - 0.413431
 - 0.439747
 - 0.467739
 - 0.497512
 - 0.52918
 - 0.562864
 - 0.598692
 - 0.636801
 - 0.677336
 - 0.72045
 - 0.766309
 - 0.815088
 - 0.866971
 - 0.922156
 - 0.980855
 - 1.04329
 - 1.1097
 - 1.18033
 - 1.25547
 - 1.33538
 - 1.42038
 - 1.5108
 - 1.60696
 - 1.70925
 - 1.81805
 - 1.93378
 - 2.05687
 - 2.18779
 - 2.32705
 - 2.47518
 - 2.63273
 - 2.80031
 - 2.97856
 - 3.16816
 - 3.36982
 - 3.58432
 - 3.81248
 - 4.05516
 - 4.31328
 - 4.58784
 - 4.87987
 - 5.19049
 - 5.52088
 - 5.8723
 - 6.24609
 - 6.64368
 - 7.06657
 - 7.51638
 - 7.99483
 - 8.50372
 - 9.04501
 - 9.62076
 - 10.2332
 - 10.8845
 - 11.5774
 - 12.3143
 - 13.0982
 - 13.9319
 - 14.8187
 - 15.762
 - 16.7653
 - 17.8324
 - 18.9675
 - 20.1749
 - 21.4591
 - 22.825
 - 24.2779
 - 25.8233
 - 27.467
 - 29.2154
 - 31.075
 - 33.0531
 - 35.157
 - 37.3949
 - 39.7752
 - 42.307
 - 45.

# Advanced settings tuning the process routine:
advanced_settings:
  # Use parallel sub-processes to speed up the execution (true or false). Advanced users
  # can also provide a numeric value > 0 to tune the number of processes in the Pool 
  # (https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool)
  multi_process: false
  # Set the size, in number of segments, of each chunk of data that will be loaded from 
  # the database. Increasing this number speeds up the load but also increases memory 
  # usage. Null means: set the chunk size automatically (600 if the number N of 
  # segments to be processed is > 600, otherwise N/10). If multi_process is on, the
  # chunk size also defines how many segments will be loaded in each Python sub-process.
  segments_chunksize: null
  # Optional arguments for the output writer. For HDF output see:
  # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.HDFStore.append.html
  # (the parameters 'append' and 'value' will be ignored, if given here)
  # For the CSV format (with or without header), see:
  # https://docs.python.org/3/library/csv.html#csv.writer
  # For CSV with header (e.g. your processing function returns dicts):
  # https://docs.python.org/3/library/csv.html#csv.DictWriter
  # (the parameters 'f', 'fieldnames' and 'csvfile' will be ignored, if given here)   
  writer_options:
    # # This parameter is empty by default. Here below some examples (commented) for HDF:
    # chunksize: 10000
    # # hdf needs a fixed length for all columns: if you write string columns
    # # you need to tell in advance the size allocated with 'min_itemsize', e.g:
    # min_itemsize:
    #   network: 2
    #   station: 5
    #   location: 2
    #   channel: 3
